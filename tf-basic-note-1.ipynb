{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF 基础和运算\n",
    "\n",
    "TF 的基本知识的笔记，灵感来自于 [Stanford CS20si 课程](http://web.stanford.edu/class/cs20si/syllabus.html)，enjoy！\n",
    "\n",
    "1.什么是 tensor?\n",
    "- ndarray\n",
    "\n",
    "2.TF 将图的定义和执行分开\n",
    "- 组装图\n",
    "- 使用 Session 来执行\n",
    "\n",
    "3.TF graph 的组成\n",
    "- nodes: operators, variables, constants\n",
    "- edges: tensors\n",
    "\n",
    "4.Session 的作用是什么？\n",
    "- 封装运行时环境，使得 op 被执行，tensor 的值被计算\n",
    "- 为当前的变量值分配内存\n",
    "\n",
    "5.为什么使用图？\n",
    "- 节省计算，计算时只需要关注变量所依赖的子图\n",
    "- 将计算拆分为小的、更容易微分的部分，这样 TF 就容易计算每个节点的导数\n",
    "- 分布式计算，将互不依存的图分配到不同的计算节点上\n",
    "- 许多机器学习模型都可以使用计算图表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将部分的运算分布到不同的计算节点\n",
    "# Creates a graph.\n",
    "with tf.device('/gpu:2'):\n",
    "  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], name='a')\n",
    "  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], name='b')\n",
    "  c = tf.multiply(a, b)\n",
    "\n",
    "# Creates a session with log_device_placement set to True.\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "\n",
    "# Runs the op.\n",
    "print(sess.run(c))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # 设置后，程序执行时就不会出现 warning\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最简单的 TF 程序\n",
    "a = tf.constant(2, name='a')\n",
    "b = tf.constant(3, name='b')\n",
    "x = tf.add(a, b, name='add')\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 Tensorboard 来查看计算图。\n",
    "# summary writer 在图定义好之后、session 运行前创建，这样才会记录所有的图内容\n",
    "# 使用命令 tensorboard --logdir='./graphs' --port 6006 来运行 tensorboard\n",
    "# 在浏览器中查看\n",
    "\n",
    "a = tf.constant(2, name='a')\n",
    "b = tf.constant(3, name='b')\n",
    "x = tf.add(a, b, name='add')\n",
    "\n",
    "writer = tf.summary.FileWriter('./graphs', tf.get_default_graph())\n",
    "writer.close()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 常量 constant 操作\n",
    "\n",
    "# 定义常量\n",
    "const = tf.constant([[0, 1], [2, 3]], name='const')\n",
    "# 全零常量，类似于 numpy.zeros\n",
    "zeros = tf.zeros([2, 3], tf.float32, name='zeros')\n",
    "# 全零常量，类似于 numpy.zeros_like\n",
    "zeros_like = tf.zeros_like(zeros, dtype=tf.int32, name='zeros_like')\n",
    "# 全 1 常量，类似于 numpy.ones\n",
    "ones = tf.ones([2, 3], tf.float32, name='ones')\n",
    "# 全 1 常量，类似于 numpy.ones_like\n",
    "ones_like = tf.ones_like(ones, dtype=tf.int32, name='ones_like')\n",
    "# 填充常量，类似于 numpy.full\n",
    "fill = tf.fill([2, 3], 8, name='fill') # [[8, 8, 8], [8, 8, 8]]\n",
    "# 定义常量序列\n",
    "lin_space = tf.lin_space(10.0, 14.0, 10, name='linspace')\n",
    "rang = tf.range(2, 18, 3, name='range') # 注意，和 np 不一样的是，这里的 rang 不能迭代，for _ in tf.range(4): # TypeError\n",
    "# 给常量赋随机值\n",
    "tf.random_normal\n",
    "tf.truncated_normal\n",
    "tf.random_uniform\n",
    "tf.random_shuffle\n",
    "tf.random_crop\n",
    "tf.random_gamma\n",
    "# 设置随机种子\n",
    "tf.set_random_seed(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数学操作\n",
    "\n",
    "# tensorflow 里面有非常多的除法操作，但都大同小异，faint！\n",
    "a = tf.constant([2, 2], name='a')\n",
    "b = tf.constant([[0, 1], [2, 3]], name='b')\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(tf.div(b, a)))             # ⇒ [[0 0] [1 1]]\n",
    "    print(sess.run(tf.divide(b, a)))          # ⇒ [[0. 0.5] [1. 1.5]]\n",
    "    print(sess.run(tf.truediv(b, a)))         # ⇒ [[0. 0.5] [1. 1.5]]\n",
    "    print(sess.run(tf.floordiv(b, a)))        # ⇒ [[0 0] [1 1]]\n",
    "    print(sess.run(tf.realdiv(b, a)))         # ⇒ # Error: only works for real values\n",
    "    print(sess.run(tf.truncatediv(b, a)))     # ⇒ [[0 0] [1 1]]\n",
    "    print(sess.run(tf.floor_div(b, a)))       # ⇒ [[0 0] [1 1]]\n",
    "\n",
    "# 多个 tensor 相加\n",
    "a = tf.constant([10, 20], name='a')\n",
    "b = tf.constant([2, 3], name='b')\n",
    "tf.add_n([a, b, b]) # ⇒ a + b + b\n",
    "\n",
    "# 两种乘法操作\n",
    "tf.multiply(a, b) # ⇒ [20 60] element-wise\n",
    "tf.tensordot(a, b, 1) # ⇒ 80，这里的 1 表示矩阵相乘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf 的数据类型\n",
    "# tf 的数据类型和 np 的数据类型无缝衔接\n",
    "tf.int32 == np.int32 # true\n",
    "tf.ones([2, 2], np.float32) # [[1.0 1.0], [1.0 1.0]]\n",
    "tf.Session.run(fetches) # 如果 fetch 是个 tensor，则输出是 numpy ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf 中的变量\n",
    "# 常量有啥问题？\n",
    "# 1.常量不能变化，weights 和 bias 需要不断地更新，所以不能用常量。\n",
    "# 2.常量的值是存在 graph 中的，当常量的数量非常多，例如 weight 有几百万个值，加载 graph 就会非常缓慢。变量是存在 parameter server 中的。\n",
    "\n",
    "# graph 是用 protobuf 格式存储的\n",
    "# protobuf = protocol buffer, Google's language-neutral, platform-neutral, extensible mechanism for serializing structured data – think XML, but smaller, faster, and simpler.\n",
    "# 打印出 graph 的 protobuf：\n",
    "print(tf.get_default_graph().as_graph_def())\n",
    "\n",
    "# 设置变量的值\n",
    "# 不推荐的方法\n",
    "s = tf.Variable(2, name=\"scalar\")\n",
    "m = tf.Variable([[0, 1], [2, 3]], name=\"matrix\")\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "# 推荐的方法，使用 tf.get_variable 来定义变量\n",
    "s = tf.get_variable(\"scalar\", initializer=tf.constant(2))\n",
    "m = tf.get_variable(\"matrix\", initializer=tf.constant([[0, 1], [2, 3]]))\n",
    "W = tf.get_variable(\"big_matrix\", shape=(784, 10), initializer=tf.zeros_initializer())\n",
    "# 为什么 tf.Variable 首字母是大写，tf.constant 是小写\n",
    "# - 因为 tf.constant 是操作，tf.Variable 是类\n",
    "\n",
    "# 变量的一些操作\n",
    "x.initializer\n",
    "x.value() # 读操作\n",
    "x.assign(...) # 赋值操作\n",
    "\n",
    "# 在 sess 执行阶段，变量需要初始化，否则会报错\n",
    "# FailedPreconditionError: Attempting to use uninitialized value Variable\n",
    "# 初始化最简单的方式\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer()) # initializer 是一个 op，需要在 sess 中才能执行\n",
    "    # 或者列出需要初始化的变量\n",
    "    sess.run(tf.variables_initializer([s, m]))\n",
    "    # 或者单独地初始化\n",
    "    sess.run(s.initializer)\n",
    "\n",
    "# 查看变量的值，使用 eval\n",
    "W = tf.Variable(tf.truncated_normal([700, 10]))\n",
    "with tf.Session() as sess:\n",
    "    sess.run(W.initializer)\n",
    "    print(W) # <tf.Variable 'Variable:0' shape=(700, 10) dtype=float32_ref>\n",
    "    print(W.eval()) # [[ 7.5906491e-01 -6.2605661e-01  1.8686393e-02 ...\n",
    "    print(sess.run(W)) # 同上\n",
    "    \n",
    "# 给变量赋值，使用 assign\n",
    "W = tf.Variable(10)\n",
    "assign_op = W.assign(100) # 注意，这里定义了一个 op，需要在 sess 中执行，才能对 W 赋值。如果不执行该 op，将不会生效。\n",
    "assign_times_two = W.assign(2 * W)\n",
    "assign_add = W.assign_add(10)\n",
    "assign_sub = W.assign_sub(2)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(W.initializer)\n",
    "    sess.run(assign_op)\n",
    "    print(W.eval()) # >> 100\n",
    "    sess.run(assign_times_two) # 多次操作\n",
    "    print(W.eval()) # >> 200\n",
    "    sess.run(assign_times_two)\n",
    "    print(W.eval()) # >> 400\n",
    "\n",
    "# 每个 sess 维持自己的变量拷贝，互不干扰\n",
    "W = tf.Variable(10)\n",
    "sess1 = tf.Session()\n",
    "sess2 = tf.Session()\n",
    "sess1.run(W.initializer)\n",
    "sess2.run(W.initializer)\n",
    "print(sess1.run(W.assign_add(10))) # >> 20\n",
    "print(sess2.run(W.assign_sub(2))) # >> 8\n",
    "sess1.close()\n",
    "sess2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 控制依赖关系：指定 d,e 必须在 a,b,c 之后执行\n",
    "with g.control_dependencies([a, b, c]):\n",
    "  d = ...\n",
    "  e = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder 占位符\n",
    "# 定义 f(x, y) = 2x + y\n",
    "# 定义图的时候，并不知道具体的值是什么，就用占位符来定义\n",
    "\n",
    "# 定义一个长度为 3 的占位符\n",
    "a = tf.placeholder(tf.float32, shape=[3]) # shape 默认为 None，表示任何 shape 都可以接受。调试的时候就悲剧了。并且打乱了所有的形状推断，导致许多 op 出错。\n",
    "b = tf.constant([5,5,5], tf.float32)\n",
    "c = a + b\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(c)) # InvalidArgumentError: a doesn’t an actual value\n",
    "    # 使用字典来提供占位符的值\n",
    "    print(sess.run(c, feed_dict={a: [1,2,3]})) # [6,7,8]\n",
    "\n",
    "# 不只是 placeholder，可以通过 dict 喂任何可以喂的 tensor\n",
    "# 在调试的时候，这个方法非常有用\n",
    "a = tf.add(2, 5)\n",
    "b = tf.multiply(a, 3)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(b, feed_dict={a: 15}) # 将 a = 15 喂入 op 中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 延迟加载带来的问题\n",
    "\n",
    "# 1 普通加载的例子\n",
    "x = tf.Variable(10, name='x')\n",
    "y = tf.Variable(20, name='y')\n",
    "z = tf.add(x, y) # 执行图中的操作前，先定义好这个 op\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for _ in range(10):\n",
    "        sess.run(z)\n",
    "\n",
    "# 2 延迟加载的例子\n",
    "x = tf.Variable(10, name='x')\n",
    "y = tf.Variable(20, name='y')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for _ in range(10):\n",
    "        sess.run(tf.add(x, y)) # 这样就可以省一行代码，聪明！\n",
    "\n",
    "# 普通加载中，add 操作被添加到图中 1 次\n",
    "# 延迟加载中，add 操作被添加到图中 10 次\n",
    "# 如果成千上万次，图就会爆掉，加载会非常缓慢，这是很常见的错误"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF 的流程控制\n",
    "# TF 的图是在执行前定义好的，因此需要将每一个可能的子图定义好\n",
    "tf.group, tf.count_up_to, tf.cond, tf.case, tf.while_loop # 流程控制\n",
    "tf.equal, tf.not_equal, tf.less, tf.greater, tf.where # 比较操作\n",
    "tf.logical_and, tf.logical_not, tf.logical_or, tf.logical_xor # 逻辑位操作\n",
    "tf.is_finite, tf.is_inf, tf.is_nan, tf.Assert, tf.Print # 调试操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
