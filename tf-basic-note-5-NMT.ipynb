{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S2S and attention\n",
    "\n",
    "统计机器翻译 SMT\n",
    "- translate French -> English\n",
    "- given French sentence x, find best English y\n",
    "  - argmax_y P(y|x)\n",
    "- 使用贝叶斯公式，将问题转为\n",
    "  - argmax_y P(x|y)P(y)\n",
    "  - 前者关注翻译，但需要大量的 f-e 翻译对，不现实。将问题拆解为 词与词 之间的翻译\n",
    "  - 后者关注语言模型，即如何写出地道英语\n",
    "\n",
    "神经机器翻译 NMT\n",
    "- 使用一个神经网络\n",
    "- 架构为 sequence-to-sequence，由两个 RNN 组成\n",
    "- encoder RNN 会训练出句子的 encoding，作为 decoder 隐藏层的初始化状态\n",
    "- decoder RNN 是一个 LM，从上面的 encoding 中生成目标句子\n",
    "    - 注意，test time behavior，每次 decoder 的输出都会是下一个的输入\n",
    "    - 注意，有 embedding 层，两\n",
    "- NMT 是一个 Conditional Language Model（LM 的作用是根据 context 预测下一个词是什么）\n",
    "    - 预测的概率 P(y|x) = P(y_1|x)P(y_2|y_1, x)P(y_3|y_2, y_1, x)...,P(y_T|y_1,...,t_T-1,x)\n",
    "    - 注意，NMT 是直接预测 P(y|x)，而 SMT 将问题拆分为翻译模型和语言模型\n",
    "\n",
    "训练 NMT\n",
    "- NMT 的训练是端到端的\n",
    "- decoder 时，每次寻找每一步概率最大的词，即 greedy decoding\n",
    "- greedy decoding 每一步的预测是无法更改的，容易出错，更好的办法是用 beam search 寻找多个选择\n",
    "- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
